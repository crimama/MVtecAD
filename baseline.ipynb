{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17665,"status":"ok","timestamp":1662479926056,"user":{"displayName":"Hun","userId":"07972583068794560208"},"user_tz":-540},"id":"FOdF68J3bq2u","outputId":"de6cb70c-4b3d-4096-8331-7e81e414782d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5372,"status":"ok","timestamp":1662480140979,"user":{"displayName":"Hun","userId":"07972583068794560208"},"user_tz":-540},"id":"bXX4S2urbpMm"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from glob import glob\n","import pandas as pd\n","import numpy as np \n","from tqdm import tqdm\n","import cv2\n","\n","import os\n","import timm\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score, accuracy_score\n","import time\n","import matplotlib.pyplot as plt \n","\n","\n","device = torch.device('cuda')\n","\n","from utils.dataset import Custom_dataset\n","from model.base_model import Network\n","\n","#이미지, 라벨 데이터 로드 해 옴 \n","def load_data(path):\n","    #이미지 path \n","    train_png = np.array(sorted(glob(f'{path}/train/*.png')))\n","    test_png = np.array(sorted(glob(f'{path}/test/*.png')))\n","    \n","    #라벨 인코더 \n","    train_labels = pd.read_csv(f\"{path}/train_df.csv\")['label']\n","    label_unique = sorted(np.unique(train_labels))\n","    label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","    \n","    #라벨 \n","    train_labels = [label_unique[k] for k in train_labels]\n","    \n","    return np.array(train_png),np.array(test_png),label_unique, np.array(train_labels )\n","\n","#데이터 패스 받아서 데이터 로더로 바로 반환 \n","def make_loader(train_index,valid_index,batch_size):\n","    global train_png, train_labels \n","    train_x = train_png[train_index]\n","    train_y = train_labels[train_index]\n","    \n","    valid_x = train_png[valid_index]\n","    valid_y = train_labels[valid_index]\n","    \n","    train_dataset = Custom_dataset(train_x,train_y)\n","    valid_dataset = Custom_dataset(valid_x,valid_y)\n","\n","    train_loader = DataLoader(train_dataset,batch_size,shuffle=True)\n","    valid_loader = DataLoader(valid_dataset,batch_size,shuffle=False)\n","    return train_loader,valid_loader\n","\n","#예측, 실제 값 F1 score 계산 \n","def score_function(real,pred):\n","    score = f1_score(real,pred,average='macro')\n","    return score \n","\n","#학습 도중 모델 세이브 \n","def model_save(model,fold):\n","    torch.save(model.state_dict(),f'./saved_model/best_model_{fold}.pt')\n","\n","#init train \n","def init_train():\n","    model = Network().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n","    criterion = nn.CrossEntropyLoss()\n","    scaler = torch.cuda.amp.GradScaler()\n","    return model, optimizer, criterion, scaler \n","\n","#Train \n","def train(dataloader,model,optimizer,criterion,scaler,CFG):\n","    train_loss = 0.0\n","    train_pred = [] \n","    train_y = [] \n","    for batch in (dataloader):\n","        optimizer.zero_grad()\n","        train_loss = 0.0\n","        x = torch.tensor(batch[0],dtype=torch.float32,device=device)\n","        y = torch.tensor(batch[1],dtype=torch.long,device=device)\n","\n","        with torch.cuda.amp.autocast():\n","            pred = model(x)\n","        loss = criterion(pred,y)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        train_loss += loss.item()/len(dataloader)\n","        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","        train_y += y.detach().cpu().numpy().tolist()\n","    return train_loss, train_pred, train_y \n","\n","\n","#Evaluate \n","def evaluate(train_y, train_pred,train_loss,epoch,CFG,TIME):\n","    train_f1 = score_function(train_y,train_pred) \n","    print(f'epoch : {epoch+1}/{CFG.epochs}    time : {TIME:.0f}s/{TIME*(CFG.epochs-epoch-1):.0f}s')\n","    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n","    return train_f1 \n","\n","#Valid Evaluation \n","def valid_test(dataloader,model,loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0,0 \n","    test_pred = [] \n","    test_y = [] \n","    with torch.no_grad():\n","        for x,y in dataloader:\n","            x,y = x.to(device),y.to(device)\n","            pred = model(x) \n","            test_loss += loss_fn(pred,y).item() \n","            test_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","            test_y += y.detach().cpu().numpy().tolist()\n","        test_f1 = score_function(test_y,test_pred)\n","    test_loss /= num_batches \n","    correct /= size \n","    print(f'TEST   loss : {test_loss:.5f}    f1 : {test_f1:.5f}')\n","\n","\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":999},"executionInfo":{"elapsed":551448,"status":"error","timestamp":1662481027342,"user":{"displayName":"Hun","userId":"07972583068794560208"},"user_tz":-540},"id":"7ypNsl2kbpMq","outputId":"f6196c52-dc26-4eac-9eab-35ccc3f2a2fa"},"outputs":[],"source":["#하이퍼 파라미터들 \n","class CFG:\n","    # path = '/content/open/'\n","    path = './data/open'\n","    batch_size = 8 \n","    epochs = 25 \n","    shuffle = True \n","#data path load     \n","train_png, test_png, label_unique, train_labels = load_data(CFG.path)\n","\n","#KFold \n","kf = KFold(n_splits=5)\n","for fold,(train_index, valid_index) in enumerate(kf.split(train_png)):\n","    train_loader, valid_loader = make_loader(train_index,valid_index,CFG.batch_size)\n","    model,optimizer,criterion,scaler = init_train()\n","\n","    best = 0 \n","    loss_history = [] \n","    \n","    for epoch in tqdm(range(CFG.epochs)):\n","      start = time.time() \n","      train_loss, train_pred, train_y  = train(train_loader,model,optimizer,criterion,scaler,CFG)\n","      TIME = time.time() - start \n","      #Plot losses per epoch \n","      if epoch == 0:\n","        loss_history.append(train_loss)\n","      else:\n","        loss_history.append(train_loss)\n","        plt.plot(np.arange(epoch+1),np.array(loss_history))\n","        plt.show()\n","      #Evaluate per epoch \n","      train_f1 = evaluate(train_y,train_pred,train_loss,epoch,CFG,TIME)\n","      #Evaluate Valid per epoch \n","      valid_test(valid_loader,model,criterion)\n","  \n","      #model save \n","      if train_f1 > best:\n","        best = train_f1\n","        model_save(model,fold)\n","      \n","    \n","    "]},{"cell_type":"markdown","metadata":{"id":"GUOfl2RjbpMt"},"source":["# Inference "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPb3j0oqbpMx","outputId":"4aff71ae-e335-4860-9f34-3a74ff6a2438"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":176,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('./model/best_model_29.pt'))\n","#데이터 \n","test_dataset = Custom_dataset(np.array(test_png),np.array(['tmp']*len(test_png)),mode='test')\n","\n","test_dataloader = DataLoader(test_dataset,batch_size=CFG.batch_size,shuffle=False)\n","\n","model.eval()\n","f_pred = [] \n","\n","with torch.no_grad():\n","    for batch in (test_dataloader):\n","        x = torch.tensor(batch[0],dtype=torch.float32,device=device)\n","        with torch.cuda.amp.autocast():\n","            pred = model(x) \n","        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())\n","label_decoder = {val:key for key, val in label_unique.items()}\n","\n","f_result = [label_decoder[result] for result in f_pred]\n","submission = pd.read_csv('./data/open/sample_submission.csv')\n","submission['label'] = f_result\n","submission.to_csv('submission0906_1.csv',index=False)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc-autonumbering":true,"toc-showmarkdowntxt":true,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
