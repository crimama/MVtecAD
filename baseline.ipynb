{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "from utils.dataset import Custom_dataset\n",
    "from model.base_model import Network\n",
    "\n",
    "#이미지, 라벨 데이터 로드 해 옴 \n",
    "def load_data(path):\n",
    "    #이미지 path \n",
    "    train_png = np.array(sorted(glob(f'{path}/train/*.png')))\n",
    "    test_png = np.array(sorted(glob(f'{path}/test/*.png')))\n",
    "    \n",
    "    #라벨 인코더 \n",
    "    train_labels = pd.read_csv(\"./data/open/train_df.csv\")['label']\n",
    "    label_unique = sorted(np.unique(train_labels))\n",
    "    label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "    \n",
    "    #라벨 \n",
    "    train_labels = [label_unique[k] for k in train_labels]\n",
    "    \n",
    "    return np.array(train_png),np.array(test_png),label_unique, np.array(train_labels )\n",
    "\n",
    "#데이터 패스 받아서 데이터 로더로 바로 반환 \n",
    "def make_loader(train_index,valid_index,batch_size):\n",
    "    global train_png, train_labels \n",
    "    train_x = train_png[train_index]\n",
    "    train_y = train_labels[train_index]\n",
    "    \n",
    "    valid_x = train_png[valid_index]\n",
    "    valid_y = train_labels[valid_index]\n",
    "    \n",
    "    train_dataset = Custom_dataset(train_x,train_y)\n",
    "    valid_dataset = Custom_dataset(valid_x,valid_y)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset,batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader\n",
    "\n",
    "#예측, 실제 값 F1 score 계산 \n",
    "def score_function(real,pred):\n",
    "    score = f1_score(real,pred,average='macro')\n",
    "    return score \n",
    "\n",
    "#학습 도중 모델 세이브 \n",
    "def model_save(model,epoch):\n",
    "    torch.save(model.state_dict(),f'./saved_model/best_model_{epoch}.pt')\n",
    "\n",
    "\n",
    "    \n",
    "def train(train_loader):\n",
    "    global model optimizer, scaler, loss_history,epoch \n",
    "    start = time.time()\n",
    "    train_loss = 0 \n",
    "    train_pred = [] \n",
    "    train_y = [] \n",
    "    model.train() \n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0],dtype=torch.float32,device=device)\n",
    "        y = torch.tensor(batch[1],dtype=torch.long,device=device)\n",
    "        with torch.cuda.amp.autocast(): #<-- mixed precision \n",
    "            pred = model(x)\n",
    "        loss = criterion(pred,y) \n",
    "        \n",
    "        scaler.scale(loss).backward() \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    \n",
    "    #plot_losses \n",
    "    if epoch ==0:\n",
    "        loss_history.append(train_loss)\n",
    "    else:\n",
    "        loss_history.append(train_loss)\n",
    "        plt.plot(np.arange(epoch+1),np.array(loss_history))\n",
    "        \n",
    "        \n",
    "    #Evaluate \n",
    "    train_f1 = score_function(train_y,train_pred) \n",
    "    \n",
    "    #model save \n",
    "    if train_f1 > best:\n",
    "        best = train_f1 \n",
    "        model_save(model,epoch)\n",
    "        \n",
    "    TIME = time.time() - start \n",
    "    \n",
    "    print(f'epoch : {epoch+1}/{CFG.epochs}    time : {TIME:.0f}s/{TIME*(CFG.epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [01:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/MVtecAD/baseline.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m loss_history \u001b[39m=\u001b[39m [] \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(CFG\u001b[39m.\u001b[39mepochs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     train(train_loader)\n",
      "\u001b[1;32m/data/MVtecAD/baseline.ipynb 셀 2\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m train_f1 \u001b[39m=\u001b[39m score_function(train_y,train_pred) \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#model save \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m train_f1 \u001b[39m>\u001b[39m best:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     best \u001b[39m=\u001b[39m train_f1 \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726963656c6573735f7065726c6d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475227d7d/data/MVtecAD/baseline.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     model_save(model,epoch)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'best' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#하이퍼 파라미터들 \n",
    "class CFG:\n",
    "    path = './data/open'\n",
    "    batch_size = 8 \n",
    "    epochs = 25 \n",
    "    shuffle = True \n",
    "#data path load     \n",
    "train_png, test_png, label_unique, train_labels = load_data(CFG.path)\n",
    "\n",
    "#KFold \n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, valid_index in kf.split(train_png):\n",
    "    train_loader, valid_loader = make_loader(train_index,valid_index,CFG.batch_size)\n",
    "\n",
    "    #학습 전 세팅 \n",
    "    model = Network().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best = 0 \n",
    "    loss_history = [] \n",
    "\n",
    "    for epoch in tqdm(range(CFG.epochs)):\n",
    "        \n",
    "        train(train_loader)\n",
    "        valid(valid_loader)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/best_model_29.pt'))\n",
    "#데이터 \n",
    "test_dataset = Custom_dataset(np.array(test_png),np.array(['tmp']*len(test_png)),mode='test')\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=CFG.batch_size,shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "f_pred = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_dataloader):\n",
    "        x = torch.tensor(batch[0],dtype=torch.float32,device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x) \n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())\n",
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]\n",
    "submission = pd.read_csv('./data/open/sample_submission.csv')\n",
    "submission['label'] = f_result\n",
    "submission.to_csv('submission0906_1.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
